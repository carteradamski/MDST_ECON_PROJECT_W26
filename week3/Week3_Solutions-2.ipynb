{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edf04945",
   "metadata": {},
   "source": [
    "# Week 3 — Universal Feature Engineering (40–60 minutes)\n",
    " Works for **monthly or quarterly** datasets\n",
    "\n",
    "## Today’s goals\n",
    "1) Create features: lags, diffs, % changes, rolling means\n",
    "2) Compare levels vs changes\n",
    "3) Explore a lag relationship\n",
    "4) Write a short explanation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f055a3",
   "metadata": {},
   "source": [
    "## Quick Python Basics Recap (for this week)\n",
    "\n",
    "This notebook assumes **you are still new to Python**. Below is the minimum syntax you need today.\n",
    "\n",
    "### DataFrames (pandas)\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"your_file.csv\")\n",
    "df.head()            # shows first rows\n",
    "df.columns           # column names\n",
    "df[\"col_name\"]       # select one column (a Series)\n",
    "df[[\"a\",\"b\"]]        # select multiple columns (a DataFrame)\n",
    "df.isna().sum()      # missing values per column\n",
    "```\n",
    "\n",
    "### Making plots (matplotlib)\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df[\"x\"], df[\"y\"])   # line plot\n",
    "plt.title(\"Title\")\n",
    "plt.xlabel(\"x label\")\n",
    "plt.ylabel(\"y label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/example.png\", dpi=150)\n",
    "plt.show()\n",
    "```\n",
    "Key idea: **You build a plot step-by-step**, then save it with `savefig`.\n",
    "\n",
    "### Writing comments\n",
    "- Use `#` for a comment on one line.\n",
    "- In this course, you must explain what your code does and what you learned from each plot.\n",
    "\n",
    "### Strings and f-strings (for readable printing)\n",
    "```python\n",
    "value = 3.14\n",
    "print(f\"The value is {value}\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7192ead2",
   "metadata": {},
   "source": [
    "## Final Project Artifacts (you must create these)\n",
    "\n",
    "By the end of this notebook, you must have:\n",
    "1. At least **2 saved figures** in the `figures/` folder (PNG files).\n",
    "2. A short **Insights** write-up answering: What changed? What matters? What would you model next?\n",
    "\n",
    "If you cannot find `figures/`, create it using:\n",
    "```python\n",
    "import os\n",
    "os.makedirs(\"figures\", exist_ok=True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef7fa71",
   "metadata": {},
   "source": [
    "## Syntax Toolbox for Week 3 (Feature Engineering)\n",
    "\n",
    "You will see these pandas patterns later. Here is the syntax **before** we use it.\n",
    "\n",
    "### 1) Creating a new column\n",
    "```python\n",
    "df[\"new_col\"] = df[\"old_col\"] * 100\n",
    "```\n",
    "\n",
    "### 2) Percent change (`pct_change`)\n",
    "```python\n",
    "df[\"unrate_pct\"] = df[\"UNRATE\"].pct_change() * 100\n",
    "```\n",
    "- `pct_change()` computes `(current - previous) / previous`.\n",
    "\n",
    "### 3) Difference (`diff`)\n",
    "```python\n",
    "df[\"unrate_diff\"] = df[\"UNRATE\"].diff()\n",
    "```\n",
    "- `diff()` computes `current - previous`.\n",
    "\n",
    "### 4) Rolling mean (`rolling`)\n",
    "```python\n",
    "df[\"unrate_roll4\"] = df[\"UNRATE\"].rolling(window=4).mean()\n",
    "```\n",
    "- A rolling mean smooths short-term noise.\n",
    "\n",
    "### 5) Lag features (`shift`)\n",
    "```python\n",
    "df[\"unrate_lag1\"] = df[\"UNRATE\"].shift(1)\n",
    "```\n",
    "- Lag features shift values down so the model can use the past.\n",
    "\n",
    "### 6) Dropping missing values created by features\n",
    "```python\n",
    "df_feat = df.dropna()\n",
    "```\n",
    "- `pct_change`, `diff`, `rolling`, and `shift` create `NaN` at the start.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69d5c43",
   "metadata": {},
   "source": [
    "> **Expanded version** (generated 2026-01-05). Added extra coding + commenting + writing tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9927b0",
   "metadata": {},
   "source": [
    "## 1) Setup + load your dataset (10–15 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fab09a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed (first time only):\n",
    "# !pip -q install pandas_datareader scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (11, 4)  # Create a plot for interpretation / reporting\n",
    "plt.rcParams[\"axes.grid\"] = True  # Create a plot for interpretation / reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c727107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "# - Goal: Run and understand the steps below\n",
    "# - What you should check after running:\n",
    "#   1) The output has the expected shape/columns\n",
    "#   2) The values look reasonable (no obvious NaNs or impossible values)\n",
    "#   3) Any figures have clear titles/labels and are saved to disk when required\n",
    "#\n",
    "# How to read this code:\n",
    "# - Imports / configuration come first\n",
    "# - Then we compute intermediate variables (feature engineering)\n",
    "# - Then we summarize / visualize\n",
    "# - Finally, we write a short interpretation in Markdown below the figure/table\n",
    "\n",
    "from pandas_datareader import data as pdr\n",
    "\n",
    "def fetch_fred_series(series_id: str, start=\"1990-01-01\", end=None) -> pd.DataFrame:\n",
    "    \"\"\"Fetch one FRED series as a DataFrame with a datetime index.\"\"\"\n",
    "    if end is None:\n",
    "        end = pd.Timestamp.today().strftime(\"%Y-%m-%d\")\n",
    "    s = pdr.DataReader(series_id, \"fred\", start, end)\n",
    "    s.columns = [series_id]\n",
    "    s.index = pd.to_datetime(s.index)  # Ensure date/time column is parsed correctly\n",
    "    return s\n",
    "\n",
    "def fetch_many(series_ids, start=\"1990-01-01\"):\n",
    "    dfs = [fetch_fred_series(s, start=start) for s in series_ids]\n",
    "    return pd.concat(dfs, axis=1).sort_index()\n",
    "\n",
    "def infer_freq(index: pd.DatetimeIndex) -> str:\n",
    "    f = pd.infer_freq(index)\n",
    "    if f is None:\n",
    "        return \"U\"\n",
    "    f = f.upper()\n",
    "    if \"Q\" in f:\n",
    "        return \"Q\"\n",
    "    if \"M\" in f:\n",
    "        return \"M\"\n",
    "    return \"U\"\n",
    "\n",
    "def to_period_end(df: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "    # Default: last observation within each period.\n",
    "    if target == \"M\":\n",
    "        return df.resample(\"M\").last()\n",
    "    if target == \"Q\":\n",
    "        return df.resample(\"Q\").last()\n",
    "    raise ValueError(\"target must be 'M' or 'Q'\")\n",
    "\n",
    "def add_common_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in out.columns:\n",
    "        out[f\"{c}_lag1\"] = out[c].shift(1)\n",
    "        out[f\"{c}_diff1\"] = out[c].diff(1)\n",
    "        out[f\"{c}_pct1\"] = out[c].pct_change(1) * 100\n",
    "        out[f\"{c}_roll3\"] = out[c].rolling(3).mean()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7ee045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# STUDENT CHOICE (EDIT HERE)\n",
    "# ===========================\n",
    "# Choose 3–6 FRED series IDs relevant to your question.\n",
    "# Search on https://fred.stlouisfed.org and copy the series ID.\n",
    "\n",
    "series_ids = [\n",
    "    \"UNRATE\",\n",
    "    \"CPIAUCSL\",\n",
    "    \"FEDFUNDS\"\n",
    "]\n",
    "\n",
    "# Choose your target variable (must be one of the series_ids)\n",
    "target_id = \"CPIAUCSL\"\n",
    "\n",
    "start_date = \"1990-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2c8c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = fetch_many(series_ids, start=start_date)\n",
    "\n",
    "# Infer each series' frequency\n",
    "freqs = {c: infer_freq(df_raw[c].dropna().index) for c in df_raw.columns}  # Handle missing values\n",
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ac80ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule: if any series is quarterly, use quarterly for everything (safe when mixing).\n",
    "use_freq = \"Q\" if any(v == \"Q\" for v in freqs.values()) else \"M\"\n",
    "print(\"Using frequency:\", use_freq)\n",
    "\n",
    "df = to_period_end(df_raw, use_freq)\n",
    "\n",
    "# Drop rows where target is missing (we can’t model without target)\n",
    "df = df.dropna(subset=[target_id])  # Handle missing values\n",
    "\n",
    "# Missing-value strategies:\n",
    "df_complete = df.dropna()                 # simplest: keep only complete rows\n",
    "df_ffill = df.fillna(method=\"ffill\")      # common: forward-fill predictors\n",
    "\n",
    "#  Choose ONE:\n",
    "df_use = df_complete   # or df_ffill\n",
    "\n",
    "df_use.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1811ec8",
   "metadata": {},
   "source": [
    "## 2) Create engineered features (10 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b83831",
   "metadata": {},
   "source": [
    "### Function Writing (Required)\n",
    "\n",
    "You will write two reusable functions. This is a core Python skill.\n",
    "\n",
    "## A) `make_features(df, col, window)`\n",
    "**Goal:** create new columns from one base column (percent change, difference, rolling mean).\n",
    "\n",
    "### Syntax you need\n",
    "**Function header**\n",
    "```python\n",
    "def my_function(arg1, arg2):\n",
    "    # body (indented)\n",
    "    return something\n",
    "```\n",
    "\n",
    "**Creating a new column in a DataFrame**\n",
    "```python\n",
    "df[\"new_name\"] = df[col].pct_change() * 100\n",
    "```\n",
    "\n",
    "### Example (tiny)\n",
    "```python\n",
    "tiny = pd.DataFrame({\"x\": [10, 11, 12, 15]})\n",
    "tiny[\"x_pct\"] = tiny[\"x\"].pct_change() * 100\n",
    "tiny\n",
    "```\n",
    "\n",
    "## B) `make_lags(df, col, lags)`\n",
    "**Goal:** create lag columns like `col_lag1`, `col_lag2`, ...\n",
    "\n",
    "### Syntax you need\n",
    "```python\n",
    "df[\"x_lag1\"] = df[\"x\"].shift(1)\n",
    "```\n",
    "\n",
    "### Example (tiny)\n",
    "```python\n",
    "tiny[\"x_lag1\"] = tiny[\"x\"].shift(1)\n",
    "tiny\n",
    "```\n",
    "\n",
    "When you are done, you should be able to call:\n",
    "```python\n",
    "df_feat = make_features(df, target_col, window=4)\n",
    "df_feat = make_lags(df_feat, target_col, lags=[1,2,3,4])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45652253",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO (STUDENTS):\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def make_features(df, cols):\n",
    "    \"\"\"Create engineered features for each column in cols.\"\"\"\n",
    "    df = df.copy()\n",
    "    # TODO\n",
    "    return df\n",
    "\n",
    "def make_lags(df, col, lags):\n",
    "    \"\"\"Create lag features for `col` for each lag in `lags`.\"\"\"\n",
    "    df = df.copy()\n",
    "    # TODO\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "# - Goal: Run and understand the steps below\n",
    "# - What you should check after running:\n",
    "#   1) The output has the expected shape/columns\n",
    "#   2) The values look reasonable (no obvious NaNs or impossible values)\n",
    "#   3) Any figures have clear titles/labels and are saved to disk when required\n",
    "#\n",
    "# How to read this code:\n",
    "# - Imports / configuration come first\n",
    "# - Then we compute intermediate variables (feature engineering)\n",
    "# - Then we summarize / visualize\n",
    "# - Finally, we write a short interpretation in Markdown below the figure/table\n",
    "\n",
    "# SOLUTION (INSTRUCTOR): Example implementation scaffold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_cols = df_use.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(\"Numeric columns:\", num_cols[:10])\n",
    "\n",
    "# Choose columns safely\n",
    "col = num_cols[0]\n",
    "fig, ax = plt.subplots(figsize=(10,4))  # Create a plot for interpretation / reporting\n",
    "df_use[col].plot(ax=ax)  # Create a plot for interpretation / reporting\n",
    "ax.set_title(f\"Example plot for {col}\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Value\")\n",
    "fig.tight_layout()\n",
    "plt.show()  # Create a plot for interpretation / reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad96eb6",
   "metadata": {},
   "source": [
    "###  Quick Test (Required)\n",
    "Add **3 assertions** proving your functions work (new columns exist, row counts, shift correctness).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37813c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO:\n",
    "# assert ...\n",
    "# assert ...\n",
    "# assert ...\n",
    "print(\" checks passed (once you complete them)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87396037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "# - Goal: Run and understand the steps below\n",
    "# - What you should check after running:\n",
    "#   1) The output has the expected shape/columns\n",
    "#   2) The values look reasonable (no obvious NaNs or impossible values)\n",
    "#   3) Any figures have clear titles/labels and are saved to disk when required\n",
    "#\n",
    "# How to read this code:\n",
    "# - Imports / configuration come first\n",
    "# - Then we compute intermediate variables (feature engineering)\n",
    "# - Then we summarize / visualize\n",
    "# - Finally, we write a short interpretation in Markdown below the figure/table\n",
    "\n",
    "df_feat = add_common_features(df_use[series_ids]).dropna()  # Handle missing values\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18b2af8",
   "metadata": {},
   "source": [
    "## 3) Choose your target form (5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4f1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "# - Goal: Run and understand the steps below\n",
    "# - What you should check after running:\n",
    "#   1) The output has the expected shape/columns\n",
    "#   2) The values look reasonable (no obvious NaNs or impossible values)\n",
    "#   3) Any figures have clear titles/labels and are saved to disk when required\n",
    "#\n",
    "# How to read this code:\n",
    "# - Imports / configuration come first\n",
    "# - Then we compute intermediate variables (feature engineering)\n",
    "# - Then we summarize / visualize\n",
    "# - Finally, we write a short interpretation in Markdown below the figure/table\n",
    "\n",
    "y_level = df_feat[target_id]\n",
    "y_pct = df_feat[f\"{target_id}_pct1\"]\n",
    "y_diff = df_feat[f\"{target_id}_diff1\"]\n",
    "\n",
    "# TODO: choose ONE\n",
    "y = y_pct\n",
    "y.name = \"y\"\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcfcc64",
   "metadata": {},
   "source": [
    "## 4) Compare: levels vs changes (15–20 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f2380b",
   "metadata": {},
   "source": [
    "###  Deeper Comparison (Required)\n",
    "Create **3 scatter plots**:\n",
    "1) y level vs X level  \n",
    "2) y change vs X change  \n",
    "3) y change vs lagged X change (choose 1 lag)\n",
    "\n",
    "Add a best-fit line for each and write 2–3 bullets interpreting each plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58aac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO:\n",
    "# Make the 3 scatter plots described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209d2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "# - Goal: Run and understand the steps below\n",
    "# - What you should check after running:\n",
    "#   1) The output has the expected shape/columns\n",
    "#   2) The values look reasonable (no obvious NaNs or impossible values)\n",
    "#   3) Any figures have clear titles/labels and are saved to disk when required\n",
    "#\n",
    "# How to read this code:\n",
    "# - Imports / configuration come first\n",
    "# - Then we compute intermediate variables (feature engineering)\n",
    "# - Then we summarize / visualize\n",
    "# - Finally, we write a short interpretation in Markdown below the figure/table\n",
    "\n",
    "predictor_id = [s for s in series_ids if s != target_id][0]\n",
    "\n",
    "plt.figure()  # Create a plot for interpretation / reporting\n",
    "plt.scatter(df_feat[predictor_id], df_feat[target_id], alpha=0.5)  # Create a plot for interpretation / reporting\n",
    "plt.title(f\"Levels: {predictor_id} vs {target_id}\")  # Create a plot for interpretation / reporting\n",
    "plt.xlabel(predictor_id); plt.ylabel(target_id)  # Create a plot for interpretation / reporting\n",
    "plt.show()  # Create a plot for interpretation / reporting\n",
    "\n",
    "plt.figure()  # Create a plot for interpretation / reporting\n",
    "plt.scatter(df_feat[f\"{predictor_id}_pct1\"], df_feat[f\"{target_id}_pct1\"], alpha=0.5)  # Create a plot for interpretation / reporting\n",
    "plt.title(f\"Changes: {predictor_id}_pct1 vs {target_id}_pct1\")  # Create a plot for interpretation / reporting\n",
    "plt.xlabel(f\"{predictor_id}_pct1\"); plt.ylabel(f\"{target_id}_pct1\")  # Create a plot for interpretation / reporting\n",
    "plt.show()  # Create a plot for interpretation / reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602ad6d7",
   "metadata": {},
   "source": [
    "**Instructor note:** explain drift vs movement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90194328",
   "metadata": {},
   "source": [
    "## 5) Lag exploration (10 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fff271c",
   "metadata": {},
   "source": [
    "###  Lag Selection Mini-Experiment (Required)\n",
    "Test multiple lags and build a results table:\n",
    "- lag\n",
    "- correlation\n",
    "- abs correlation\n",
    "\n",
    "Sort by abs correlation and pick the best lag. Explain why.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b34b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO:\n",
    "# lags = [...]\n",
    "# rows = []\n",
    "# for lag in lags:\n",
    "#     ...\n",
    "# lag_results = pd.DataFrame(rows).sort_values(\"abs_corr\", ascending=False)\n",
    "# display(lag_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef45e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "# - Goal: Run and understand the steps below\n",
    "# - What you should check after running:\n",
    "#   1) The output has the expected shape/columns\n",
    "#   2) The values look reasonable (no obvious NaNs or impossible values)\n",
    "#   3) Any figures have clear titles/labels and are saved to disk when required\n",
    "#\n",
    "# How to read this code:\n",
    "# - Imports / configuration come first\n",
    "# - Then we compute intermediate variables (feature engineering)\n",
    "# - Then we summarize / visualize\n",
    "# - Finally, we write a short interpretation in Markdown below the figure/table\n",
    "\n",
    "plt.figure()  # Create a plot for interpretation / reporting\n",
    "plt.scatter(df_feat[f\"{predictor_id}_lag1\"], df_feat[f\"{target_id}_pct1\"], alpha=0.5)  # Create a plot for interpretation / reporting\n",
    "plt.title(f\"Lag: {predictor_id}_lag1 vs {target_id}_pct1\")  # Create a plot for interpretation / reporting\n",
    "plt.xlabel(f\"{predictor_id}_lag1\"); plt.ylabel(f\"{target_id}_pct1\")  # Create a plot for interpretation / reporting\n",
    "plt.show()  # Create a plot for interpretation / reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e6189a",
   "metadata": {},
   "source": [
    "**Instructor note:** keep lag length at 1 to reduce cognitive load."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bf73f6",
   "metadata": {},
   "source": [
    "## 6) Reflection (8–10 min)\n",
    "Write 5–7 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ba703",
   "metadata": {},
   "source": [
    "**Instructor example:** Changes reduce drift; lags can capture delayed effects; rolling means smooth noise. Next: test more lags and compare models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f7a9e",
   "metadata": {},
   "source": [
    "## End-of-class checkpoint\n",
    " `df_feat` + comparisons + reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b05efce",
   "metadata": {},
   "source": [
    "## Final Project Artifacts (Save these for your report)\n",
    "\n",
    "By the end of the project, you should have:\n",
    "- At least 2 polished figures that show *trends* and *relationships*\n",
    "- A small table of your **top correlations** with the target\n",
    "- A short written interpretation of what the plots suggest\n",
    "\n",
    "In this section you will generate and save figures you can reuse in your final write-up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e54e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "# - Goal: Run and understand the steps below\n",
    "# - What you should check after running:\n",
    "#   1) The output has the expected shape/columns\n",
    "#   2) The values look reasonable (no obvious NaNs or impossible values)\n",
    "#   3) Any figures have clear titles/labels and are saved to disk when required\n",
    "#\n",
    "# How to read this code:\n",
    "# - Imports / configuration come first\n",
    "# - Then we compute intermediate variables (feature engineering)\n",
    "# - Then we summarize / visualize\n",
    "# - Finally, we write a short interpretation in Markdown below the figure/table\n",
    "\n",
    "# SOLUTION (INSTRUCTOR):\n",
    "# Save a trend figure and a relationship figure using available numeric columns.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.makedirs(\"figures\", exist_ok=True)  # Create output folder if it does not exist\n",
    "\n",
    "num_cols = df_use.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if len(num_cols) == 0:\n",
    "    raise ValueError(\"No numeric columns found in df_use. Check data loading/cleaning steps.\")\n",
    "\n",
    "# Trend figure: first numeric column\n",
    "col_trend = num_cols[0]\n",
    "fig, ax = plt.subplots(figsize=(10,4))  # Create a plot for interpretation / reporting\n",
    "df_use[col_trend].plot(ax=ax)  # Create a plot for interpretation / reporting\n",
    "ax.set_title(f\"Trend of {col_trend} over time\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Value\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"figures/trend_{col_trend}.png\", dpi=200)  # Save an artifact you can reuse in the final project\n",
    "\n",
    "# Relationship figure: correlation heatmap (top 8 numeric cols)\n",
    "use_cols = num_cols[:8]\n",
    "corr = df_use[use_cols].corr()  # Compute correlations to look for relationships\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,6))  # Create a plot for interpretation / reporting\n",
    "im = ax.imshow(corr.values)\n",
    "ax.set_xticks(range(len(use_cols)))\n",
    "ax.set_yticks(range(len(use_cols)))\n",
    "ax.set_xticklabels(use_cols, rotation=45, ha=\"right\")\n",
    "ax.set_yticklabels(use_cols)\n",
    "ax.set_title(\"Correlation heatmap (subset of variables)\")\n",
    "fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"figures/corr_heatmap.png\", dpi=200)  # Save an artifact you can reuse in the final project\n",
    "\n",
    "corr.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d481e33",
   "metadata": {},
   "source": [
    "### Written Insights (Required)\n",
    "\n",
    "Write 5–8 bullet points answering:\n",
    "1. Which variable trends most strongly over time? What might explain it?\n",
    "2. Which pair of variables looks most related? Is that relationship stable over time?\n",
    "3. What missingness or outliers could bias modeling?\n",
    "4. What is one feature engineering idea you want to try next week?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb1868e",
   "metadata": {},
   "source": [
    "#### Sample instructor bullets (example)\n",
    "\n",
    "- The first numeric series shows a clear upward trend; this suggests non-stationarity and motivates using percent change or differencing.\n",
    "- Correlation heatmap indicates several variables move together, suggesting multicollinearity; regularization may help.\n",
    "- Missingness is concentrated in a small set of columns; imputation strategy should be justified and tested.\n",
    "- Outliers appear around major economic events; consider robust scaling or winsorization and document the rationale.\n",
    "- Next week: create lag features and rolling aggregates to capture delayed effects.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Week3_Universal_Paced_Instructor",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
